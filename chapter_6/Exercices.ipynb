{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJLi9sWcYxczWTZwoBOkhE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"AJaEvUrAw-4G"}},{"cell_type":"code","source":["import yfinance as yf\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","def train_step(model, X_train, y_train, loss_function, optimizer):\n","  pred_train = model(X_train)\n","  loss = loss_function(pred_train , y_train)\n","\n","  model.zero_grad()\n","  loss.backward()\n","  optimizer.step()\n","\n","  return loss.item()\n","\n","\n","def add_original_feature(df, df_new):\n","  df_new['open'] = df['Open']\n","  df_new['open_1'] = df['Open'].shift(1)\n","  df_new['close_1'] = df['Close'].shift(1)\n","  df_new['high_1'] = df['High'].shift(1)\n","  df_new['low_1'] = df['Low'].shift(1)\n","  df_new['volume_1'] = df['Volume'].shift(1)\n","\n","\n","def add_avg_price(df,df_new):\n","  df_new['avg_price_5'] = df['Close'].rolling(window=5).mean().shift(1)\n","  df_new['avg_price_30'] = df['Close'].rolling(window=21).mean().shift(1)\n","  df_new['avg_price_365'] = df['Close'].rolling(window=252).mean().shift(1)\n","  df_new['ratio_avg_price_5_30'] = df_new['avg_price_5'] / df_new['avg_price_30']\n","  df_new['ratio_avg_price_5_365'] = df_new['avg_price_5'] / df_new['avg_price_365']\n","  df_new['ratio_avg_price_30_365'] = df_new['avg_price_30'] / df_new['avg_price_365']\n","\n","\n","def add_avg_volume(df,df_new):\n","  df_new['avg_volume_5'] = df['Volume'].rolling(window=5).mean().shift(1)\n","  df_new['avg_volume_30'] = df['Volume'].rolling(window=21).mean().shift(1)\n","  df_new['avg_volume_365'] = df['Volume'].rolling(window=252).mean().shift(1)\n","  df_new['ratio_avg_volume_5_30'] = df_new['avg_volume_5'] / df_new['avg_volume_30']\n","  df_new['ratio_avg_volume_5_365'] = df_new['avg_volume_5'] / df_new['avg_volume_365']\n","  df_new['ratio_avg_volume_30_365'] = df_new['avg_volume_30'] / df_new['avg_volume_365']\n","\n","\n","def add_std_price(df,df_new):\n","  df_new['std_price_5'] = df['Close'].rolling(window=5).mean().shift(1)\n","  df_new['std_price_30'] = df['Close'].rolling(window=21).mean().shift(1)\n","  df_new['std_price_365'] = df['Close'].rolling(window=252).mean().shift(1)\n","  df_new['ratio_std_price_5_30'] = df_new['std_price_5'] / df_new['std_price_30']\n","  df_new['ratio_std_price_5_365'] = df_new['std_price_5'] / df_new['std_price_365']\n","  df_new['ratio_std_price_30_365'] = df_new['std_price_30'] / df_new['std_price_365']\n","\n","def add_std_volume(df,df_new):\n","  df_new['std_volume_5'] = df['Close'].rolling(window=5).mean().shift(1)\n","  df_new['std_volume_30'] = df['Close'].rolling(window=21).mean().shift(1)\n","  df_new['std_volume_365'] = df['Close'].rolling(window=252).mean().shift(1)\n","  df_new['ratio_std_volume_5_30'] = df_new['std_volume_5'] / df_new['std_volume_30']\n","  df_new['ratio_std_volume_5_365'] = df_new['std_volume_5'] / df_new['std_volume_365']\n","  df_new['ratio_std_volume_30_365'] = df_new['std_volume_30'] / df_new['std_volume_365']\n","\n","\n","def add_return_feature(df,df_new):\n","  df_new['return_1'] = ((df['Close']-df['Close'].shift(1))/df['Close'].shift(1)).shift(1)\n","  df_new['return_5'] = ((df['Close']- df['Close'].shift(5))/df['Close'].shift(5)).shift(1)\n","  df_new['return_30'] = ((df['Close']- df['Close'].shift(21))/df['Close'].shift(21)).shift(1)\n","  df_new['return_365'] = ((df['Close']- df['Close'].shift(252))/df['Close'].shift(252)).shift(1)\n","  df_new['movie_avg_5'] = df_new['return_1'].rolling(window=5).mean().shift(1)\n","  df_new['movie_avg_30'] = df_new['return_1'].rolling(window=21).mean().shift(1)\n","  df_new['movie_avg_365'] = df_new['return_1'].rolling(window=252).mean().shift(1)\n","\n","\n","\n","def generate_features(df):\n","  \"\"\"\n","  Generate features for a stock/index based on historical price and\n","  performance\n","  @param df: dataframe with columns \"Open\", \"Close\", \"High\", \"Low\",\"Volume\", \"Adj Close\"\n","  @return: dataframe, data set with new features\n"," \"\"\"\n","  df_new = pd.DataFrame()\n","  #6 original features\n","  add_original_feature(df, df_new)\n","  #31 generated features\n","  add_avg_price(df, df_new)\n","  add_avg_volume(df, df_new)\n","  add_std_price(df, df_new)\n","  add_std_volume(df, df_new)\n","  add_return_feature(df, df_new)\n","  #the target\n","  df_new['close'] = df['Close']\n","  df_new = df_new.dropna()\n","  return df_new\n","\n","\n","print(\"Downloading NASDAQ Composite data (1990-2023)...\")\n","data = yf.download(\n","        \"^IXIC\",\n","        start=\"1990-01-01\",\n","        end=\"2023-06-30\",\n","        progress=False\n","    )\n","\n","data.to_csv('19900101_20230630.csv')\n","\n","data_raw = pd.read_csv('19900101_20230630.csv', header=None, index_col=0, skiprows=2)\n","\n","\n","# Assign column names to the data columns after setting the index\n","data_raw.columns = ['Close', 'High', 'Low', 'Open', 'Volume']\n","\n","# The first row after skipping headers is the actual first data entry, no need for iloc[1:]\n","\n","# Set the index name for clarity\n","data_raw.index.name = 'Date'\n","\n","# Generate features using the cleaned data\n","data = generate_features(data_raw)\n","start_train = '1990-01-01'\n","end_train = '2022-12-31'\n","start_test = '2023-01-01'\n","end_test = '2023-06-30'\n","data_train = data.loc[start_train:end_train]\n","X_train = data_train.drop('close', axis=1).values\n","y_train = data_train['close'].values\n","print(X_train.shape)\n","print(y_train.shape)\n","data_train = data.loc[start_train:end_train]\n","data_test = data.loc[start_test:end_test] # Added to get test data\n","X_test = data_test.drop('close', axis=1).values # Added to get test features\n","y_test = data_test['close'].values # Added to get test targets\n","print(X_test.shape) # Changed to print X_test shape\n","print(y_test.shape) # Added to print y_test shape"],"metadata":{"id":"OAwPfLhfxAiM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercices"],"metadata":{"id":"ncuAgsy8w78p"}},{"cell_type":"markdown","source":["1. As mentioned, can you use more hidden layers in the neural network stock predictor and rerun\n","the model fine-tuning? Can you get a better result?\n"],"metadata":{"id":"z9zGqjqrxIj8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6agruDUfw7Wd"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["2. Following the first exercise, can you apply dropout and/or early stopping and see if you can\n","beat the current best R\n","2 of 0.977?"],"metadata":{"id":"WgzpszZFxLo4"}}]}