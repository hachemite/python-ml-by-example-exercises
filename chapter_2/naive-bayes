{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["akJb5O8CWcXn"],"authorship_tag":"ABX9TyMplDO/AGV8LwYbjz9OhpKt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Naive ***bayes***"],"metadata":{"id":"qvJVTUWNf060"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"7Akb85fteFw-","executionInfo":{"status":"ok","timestamp":1753408911314,"user_tz":-60,"elapsed":36,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","source":["X_train = np.array([\n","    [0, 1, 1],\n","    [0, 0, 1],\n","    [0, 0, 0],\n","    [1, 1, 0]])\n","Y_train = ['Y', 'N', 'Y', 'Y']\n","X_test = np.array([[1, 1, 0]])"],"metadata":{"id":"6-wny8hzo6DY","executionInfo":{"status":"ok","timestamp":1753408911421,"user_tz":-60,"elapsed":80,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def get_label_indices(labels):\n","  \"\"\"\n","  Group samples based on their labels and return indices\n","  @param labels: list of labels\n","  @return: dict, {class1: [indices], class2: [indices]}\n","  \"\"\"\n","  from collections import defaultdict\n","  label_indices = defaultdict(list)\n","  for index, label in enumerate(labels):\n","    label_indices[label].append(index)\n","  return label_indices"],"metadata":{"id":"sLXzOH0gpIkA","executionInfo":{"status":"ok","timestamp":1753408911423,"user_tz":-60,"elapsed":50,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["test"],"metadata":{"id":"8j4se5A3MCVy"}},{"cell_type":"code","source":["from collections import defaultdict\n","label_indices = defaultdict(list)\n","for index, label in enumerate(Y_train):\n","  label_indices[label].append(index)\n","  print(label_indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYXxUVRoLz1S","executionInfo":{"status":"ok","timestamp":1753408911424,"user_tz":-60,"elapsed":49,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}},"outputId":"3baf1ddc-9016-4003-e905-2d166352f34a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["defaultdict(<class 'list'>, {'Y': [0]})\n","defaultdict(<class 'list'>, {'Y': [0], 'N': [1]})\n","defaultdict(<class 'list'>, {'Y': [0, 2], 'N': [1]})\n","defaultdict(<class 'list'>, {'Y': [0, 2, 3], 'N': [1]})\n"]}]},{"cell_type":"markdown","source":["result"],"metadata":{"id":"ahJzRMt2MFQw"}},{"cell_type":"code","source":["label_indices = get_label_indices(Y_train)\n","print('label_indices:\\n', label_indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylbx0Px2p4Qa","executionInfo":{"status":"ok","timestamp":1753408911425,"user_tz":-60,"elapsed":36,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}},"outputId":"8de7a1b6-5dbb-459d-9135-779a40d31cd7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["label_indices:\n"," defaultdict(<class 'list'>, {'Y': [0, 2, 3], 'N': [1]})\n"]}]},{"cell_type":"code","source":["def get_prior(label_indices):\n","  \"\"\"\n","     Compute prior based on training samples\n","     @param label_indices: grouped sample indices by class\n","     @return: dictionary, with class label as key, corresponding\n","     prior as the value\n","  \"\"\"\n","  prior = {label: len(indices) for label, indices in label_indices.items()}\n","  total_count = sum(prior.values())\n","  for label in prior:\n","    prior[label] /= total_count\n","  return prior"],"metadata":{"id":"4GwB2bfzvyvw","executionInfo":{"status":"ok","timestamp":1753408911426,"user_tz":-60,"elapsed":13,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["prior = get_prior(label_indices)\n","print('Prior:', prior)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3q7OnpR-wP6C","executionInfo":{"status":"ok","timestamp":1753408911440,"user_tz":-60,"elapsed":13,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}},"outputId":"b094ff3c-b8fa-4f35-97ff-6026f5421e4c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Prior: {'Y': 0.75, 'N': 0.25}\n"]}]},{"cell_type":"code","source":["def get_likelihood(features, label_indices, smoothing=0):\n","    \"\"\"\n","    Compute likelihood based on training samples\n","    @param features: matrix of features\n","    @param label_indices: grouped sample indices by class\n","    @param smoothing: integer, additive smoothing parameter\n","    @return: dictionary, with class as key, corresponding\n","    conditional probability P(feature|class) vector\n","    as value\n","    \"\"\"\n","    likelihood = {}\n","    num_feature_values = 2  # Assuming binary features (0/1). Change if needed.\n","\n","    for label, indices in label_indices.items():\n","        # Sum features for this class and apply smoothing\n","        feature_counts = features[indices, :].sum(axis=0) + smoothing\n","        total_samples = len(indices)\n","\n","        # Calculate probability with smoothing\n","        likelihood[label] = feature_counts / (total_samples + num_feature_values * smoothing)\n","\n","    return likelihood"],"metadata":{"id":"NuWafLhoyoXe","executionInfo":{"status":"ok","timestamp":1753408911473,"user_tz":-60,"elapsed":8,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["smoothing = 1\n","likelihood = get_likelihood(X_train, label_indices, smoothing)"],"metadata":{"id":"ZmCmdSFkyoM-","executionInfo":{"status":"ok","timestamp":1753408911478,"user_tz":-60,"elapsed":1,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["print('Likelihood:\\n', likelihood)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RwtOrNvCyus2","executionInfo":{"status":"ok","timestamp":1753408911539,"user_tz":-60,"elapsed":60,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}},"outputId":"d27e3db5-78f4-4c29-b3ae-2e217d1e4a57"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Likelihood:\n"," {'Y': array([0.4, 0.6, 0.4]), 'N': array([0.33333333, 0.33333333, 0.66666667])}\n"]}]},{"cell_type":"code","source":["def get_posterior(X, prior, likelihood):\n","    \"\"\"\n","    Compute posterior of testing samples, based on prior and likelihood\n","    @param X: testing samples\n","    @param prior: dictionary, with class label as key, corresponding prior as the value\n","    @param likelihood: dictionary, with class label as key, corresponding conditional probability vector as value\n","    @return: dictionary, with class label as key, corresponding posterior as value\n","    \"\"\"\n","    posteriors = []\n","    for x in X:\n","        # posterior is proportional to prior * likelihood\n","        posterior = prior.copy()\n","        for label, likelihood_label in likelihood.items():\n","            for index, bool_value in enumerate(x):\n","                posterior[label] *= likelihood_label[index] if bool_value else (1 - likelihood_label[index])\n","        # normalize so that all sums up to 1\n","        sum_posterior = sum(posterior.values())\n","        for label in posterior:\n","            if posterior[label] == float('inf'):\n","                posterior[label] = 1.0\n","            else:\n","                posterior[label] /= sum_posterior\n","        posteriors.append(posterior.copy())\n","    return posteriors"],"metadata":{"id":"Nna9TVpRItNR","executionInfo":{"status":"ok","timestamp":1753408911541,"user_tz":-60,"elapsed":49,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["for i in likelihood.items():\n","  print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfuGX2IWP4T7","executionInfo":{"status":"ok","timestamp":1753408911542,"user_tz":-60,"elapsed":19,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}},"outputId":"0be54737-6154-41ce-c828-26a436c7870e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["('Y', array([0.4, 0.6, 0.4]))\n","('N', array([0.33333333, 0.33333333, 0.66666667]))\n"]}]},{"cell_type":"code","source":["posterior = get_posterior(X_test, prior, likelihood)\n","print('Posterior:\\n', posterior)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SI1688MJRFz","executionInfo":{"status":"ok","timestamp":1753408911543,"user_tz":-60,"elapsed":14,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}},"outputId":"d9e1be03-3dc7-492d-ccbb-ce9de0001015"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Posterior:\n"," [{'Y': np.float64(0.9210360075805433), 'N': np.float64(0.07896399241945673)}]\n"]}]},{"cell_type":"markdown","source":["# Implementing Na√Øve Bayes with scikit-learn"],"metadata":{"id":"GimkTJus4EN4"}},{"cell_type":"code","source":["from sklearn.naive_bayes import BernoulliNB\n","\n","clf = BernoulliNB(alpha=1.0, fit_prior=True)"],"metadata":{"id":"_kAiYbwlRScA","executionInfo":{"status":"ok","timestamp":1753408914099,"user_tz":-60,"elapsed":2556,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["clf.fit(X_train, Y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"UG9lXzw-Rm0_","executionInfo":{"status":"ok","timestamp":1753408914157,"user_tz":-60,"elapsed":56,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}},"outputId":"f4c89564-ac36-40a3-d938-ab63a271a51e"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BernoulliNB()"],"text/html":["<style>#sk-container-id-1 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: #000;\n","  --sklearn-color-text-muted: #666;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-1 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-1 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-1 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-1 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-1 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-1 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-1 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-1 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: flex;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","  align-items: start;\n","  justify-content: space-between;\n","  gap: 0.5em;\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label .caption {\n","  font-size: 0.6rem;\n","  font-weight: lighter;\n","  color: var(--sklearn-color-text-muted);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"‚ñ∏\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-1 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"‚ñæ\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-1 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-1 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-1 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-1 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-1 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 0.5em;\n","  text-align: center;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-1 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-1 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BernoulliNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.BernoulliNB.html\">?<span>Documentation for BernoulliNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>BernoulliNB()</pre></div> </div></div></div></div>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["pred_prob = clf.predict_proba(X_test)\n","print('[scikit-learn] Predicted probabilities:\\n', pred_prob)"],"metadata":{"id":"2S2CqhGJRpVH","executionInfo":{"status":"ok","timestamp":1753408914204,"user_tz":-60,"elapsed":45,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f3ad5b33-a14a-4f25-b828-f430aa1f2b56"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[scikit-learn] Predicted probabilities:\n"," [[0.07896399 0.92103601]]\n"]}]},{"cell_type":"markdown","source":["## All code with math"],"metadata":{"id":"akJb5O8CWcXn"}},{"cell_type":"code","source":["\"\"\"\n","Source codes for Python Machine Learning By Example 3rd Edition (Packt Publishing)\n","Chapter 2: Building A Movie Recommendation Engine with Naive Bayes\n","Author: Yuxi (Hayden) Liu (yuxi.liu.ece@gmail.com)\n","\n","Implementation of Naive Bayes classifier with mathematical equations as comments.\n","\"\"\"\n","\n","import numpy as np\n","from collections import defaultdict\n","\n","\n","def get_label_indices(labels):\n","    \"\"\"\n","    Group samples based on their labels and return indices\n","    @param labels: list of labels\n","    @return: dict, {class1: [indices], class2: [indices]}\n","\n","    Math:\n","    For each unique class c in labels:\n","        I_c = {i | y_i = c} where y_i is the label for sample i\n","    Returns {c: list(I_c) for all classes c}\n","    \"\"\"\n","    label_indices = defaultdict(list)\n","    for index, label in enumerate(labels):\n","        label_indices[label].append(index)\n","    return label_indices\n","\n","\n","def get_prior(label_indices):\n","    \"\"\"\n","    Compute prior based on training samples\n","    @param label_indices: grouped sample indices by class\n","    @return: dictionary, with class label as key, corresponding prior as the value\n","\n","    Math:\n","    P(c) = |I_c| / N\n","    where:\n","        |I_c| = number of samples in class c\n","        N = total number of samples (sum over all |I_c|)\n","    \"\"\"\n","    prior = {label: len(indices) for label, indices in label_indices.items()}\n","    total_count = sum(prior.values())\n","    for label in prior:\n","        prior[label] /= total_count\n","    return prior\n","\n","\n","def get_likelihood(features, label_indices, smoothing=0):\n","    \"\"\"\n","    Compute likelihood based on training samples\n","    @param features: matrix of features\n","    @param label_indices: grouped sample indices by class\n","    @param smoothing: integer, additive smoothing parameter\n","    @return: dictionary, with class as key, corresponding conditional probability P(feature|class) vector as value\n","\n","    Math (with Laplace smoothing):\n","    For each class c and feature j:\n","        P(f_j = 1 | c) = (count(f_j = 1 in class c) + Œ±) / (|I_c| + 2Œ±)\n","    where:\n","        Œ± = smoothing parameter (Œ±=1 for Laplace smoothing)\n","        |I_c| = number of samples in class c\n","    \"\"\"\n","    likelihood = {}\n","    for label, indices in label_indices.items():\n","        # Sum of features for samples in this class (count of 1's)\n","        likelihood[label] = features[indices, :].sum(axis=0) + smoothing\n","        total_count = len(indices)\n","        # Apply Laplace smoothing denominator\n","        likelihood[label] = likelihood[label] / (total_count + 2 * smoothing)\n","    return likelihood\n","\n","\n","def get_posterior(X, prior, likelihood):\n","    \"\"\"\n","    Compute posterior of testing samples, based on prior and likelihood\n","    @param X: testing samples\n","    @param prior: dictionary, with class label as key, corresponding prior as the value\n","    @param likelihood: dictionary, with class label as key, corresponding conditional probability vector as value\n","    @return: dictionary, with class label as key, corresponding posterior as value\n","\n","    Math:\n","    For each test sample x = [x_1, x_2, ..., x_n]:\n","        1. Initialize posterior with prior:\n","            posterior(c) = P(c)\n","        2. Apply likelihood for each feature:\n","            posterior(c) *= ‚àè_{j=1}^n [P(f_j=1|c) if x_j=1 else (1 - P(f_j=1|c))]\n","        3. Normalize:\n","            P(c|x) = posterior(c) / sum_over_c'(posterior(c'))\n","    \"\"\"\n","    posteriors = []\n","    for x in X:\n","        # Initialize posterior with prior probabilities\n","        posterior = prior.copy()\n","\n","        # Apply likelihood for each class\n","        for label, likelihood_label in likelihood.items():\n","            for index, bool_value in enumerate(x):\n","                # Multiply by P(f_j|c) if feature is present (x_j=1)\n","                # or (1 - P(f_j|c)) if feature is absent (x_j=0)\n","                posterior[label] *= likelihood_label[index] if bool_value else (1 - likelihood_label[index])\n","\n","        # Normalize posterior probabilities\n","        sum_posterior = sum(posterior.values())\n","        for label in posterior:\n","            if posterior[label] == float('inf'):\n","                posterior[label] = 1.0  # Handle overflow case\n","            else:\n","                posterior[label] /= sum_posterior\n","\n","        posteriors.append(posterior.copy())\n","    return posteriors\n","\n","\n","if __name__ == '__main__':\n","    # Training data\n","    X_train = np.array([\n","        [0, 1, 1],\n","        [0, 0, 1],\n","        [0, 0, 0],\n","        [1, 1, 0]])\n","    Y_train = ['Y', 'N', 'Y', 'Y']\n","\n","    # Test sample\n","    X_test = np.array([[1, 1, 0]])\n","\n","    # Step 1: Group samples by class\n","    label_indices = get_label_indices(Y_train)\n","    print('label_indices:\\n', label_indices)\n","\n","    # Step 2: Compute prior probabilities P(c)\n","    prior = get_prior(label_indices)\n","    print('Prior:', prior)\n","\n","    # Step 3: Compute likelihood P(f_j|c) with Laplace smoothing (Œ±=1)\n","    smoothing = 1\n","    likelihood = get_likelihood(X_train, label_indices, smoothing)\n","    print('Likelihood:\\n', likelihood)\n","\n","    # Step 4: Compute posterior P(c|x) for test sample\n","    posterior = get_posterior(X_test, prior, likelihood)\n","    print('Posterior:\\n', posterior)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVzfMxn4WZCi","executionInfo":{"status":"ok","timestamp":1753409521221,"user_tz":-60,"elapsed":51,"user":{"displayName":"hachem squalli","userId":"05759333707596247759"}},"outputId":"b96cc455-8aea-4fea-ad09-2392e34adebd"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["label_indices:\n"," defaultdict(<class 'list'>, {'Y': [0, 2, 3], 'N': [1]})\n","Prior: {'Y': 0.75, 'N': 0.25}\n","Likelihood:\n"," {'Y': array([0.4, 0.6, 0.4]), 'N': array([0.33333333, 0.33333333, 0.66666667])}\n","Posterior:\n"," [{'Y': np.float64(0.9210360075805433), 'N': np.float64(0.07896399241945673)}]\n"]}]}]}